{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    \"\"\"\n",
    "    Algoritmo de clustering K-Means\n",
    "\n",
    "    Parametros:\n",
    "        k (int): Número de clusters a encontrar (por defecto 3)\n",
    "        max_iter (int): Número maximo de iteraciones (por defecto 100)\n",
    "        centroids (numpy.ndarray): Cordenadas iniciales del centroides (por defecto ninguna)\n",
    "    \"\"\"\n",
    "    def __init__(self, k=3, max_iter=100, centroids = None):\n",
    "        \"\"\"\n",
    "        Constructor de objetos kMeans\n",
    "\n",
    "        Parametros:\n",
    "            k (int): Número de cluster\n",
    "            max_iter (int): Número maximo de iteraciones\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "        self.centroids = centroids\n",
    "\n",
    "    def distancia_euclideana(self, p1, p2):\n",
    "        \"\"\"\n",
    "        Calcula la distancia Euclideana entre dos puntos.\n",
    "\n",
    "        Parametros:\n",
    "            point1 (numpy.ndarray): Primer punto\n",
    "            point2 (numpy.ndarray): Segundo punto\n",
    "\n",
    "        Returns:\n",
    "            float: La distancia euclideana entre los dos puntos\n",
    "        \"\"\"\n",
    "        return np.sqrt(np.sum((p1 - p2)**2))\n",
    "    \n",
    "    def distancia_manhattan(self, point1, point2):\n",
    "        \"\"\"\n",
    "        Calcula la distancia de Manhattan entre dos puntos\n",
    "\n",
    "        Parametros:\n",
    "            point1 (numpy.ndarray): Primer punto.\n",
    "            point2 (numpy.ndarray): Segundo punto\n",
    "\n",
    "        Returns:\n",
    "            float: Distancia de Manhattan entre dos puntos\n",
    "        \"\"\"\n",
    "        return np.sum(np.abs(point1 - point2))\n",
    "\n",
    "    def distancia_mahalanobis(self, point1, point2, covariance_matrix):\n",
    "        \"\"\"\n",
    "        Cacula la distancia de Mahalanobis entre dos puntos\n",
    "\n",
    "        Parametros:\n",
    "            point1 (numpy.ndarray): Primer punto.\n",
    "            point2 (numpy.ndarray): Segundo punto.\n",
    "            covariance_matrix (numpy.ndarray): Matrix de covarancia de los datos.\n",
    "\n",
    "        Returns:\n",
    "            float: La distancia de Mahalanobis entre dos puntos\n",
    "        \"\"\"\n",
    "        diff = point1 - point2\n",
    "        return np.sqrt(diff @ np.linalg.inv(covariance_matrix) @ diff.T)\n",
    "\n",
    "    def calcular_centroides(self, points, labels):\n",
    "        \"\"\"\n",
    "        Calcula los centroides de la nube de puntos dada por la asignación en la variable labels\n",
    "\n",
    "        Parametros:\n",
    "            points (numpy.ndarray): Nube de puntos\n",
    "            labels (numpy.ndarray): Cluster asignado para cada punto\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Centroides de cada cluster\n",
    "        \"\"\"\n",
    "\n",
    "        centroids = np.zeros((self.k, points.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            cluster_points = points[labels == i]\n",
    "            if len(cluster_points) > 0:\n",
    "              centroids[i] = np.mean(cluster_points, axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def run(self, points, tipo_distance='euclidean'):\n",
    "        \"\"\"\n",
    "        Ejecuta un algoritmo K-Means dado la nube de puntos recibida como parametro\n",
    "\n",
    "        Parametros:\n",
    "            points (numpy.ndarray): Nube de puntos\n",
    "            tipo_distance (str): Tipo de distancia a utilizar ('euclidean', 'manhattan', or 'mahalanobis'). Por defecto  'euclidean'.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: El cluster asignado a cada grupo\n",
    "        \"\"\"\n",
    "       \n",
    "        indices = np.random.choice(points.shape[0], self.k, replace=False)\n",
    "        self.centroids = points[indices]\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            labels = np.zeros(points.shape[0], dtype=int)\n",
    "            for i, point in enumerate(points):\n",
    "                if tipo_distance == 'euclidean':\n",
    "                    distances = [self.distancia_euclideana(point, centroid) for centroid in self.centroids]\n",
    "                elif tipo_distance == 'manhattan':\n",
    "                    distances = [self.distancia_manhattan(point, centroid) for centroid in self.centroids]\n",
    "                elif tipo_distance == 'mahalanobis':\n",
    "                    covariance_matrix = np.cov(points, rowvar=False)                 \n",
    "                    distances = [self.distancia_mahalanobis(point, centroid, covariance_matrix) for centroid in self.centroids]\n",
    "                else:\n",
    "                    raise ValueError(\"Tipo de distancia no disponible\")\n",
    "                labels[i] = np.argmin(distances)\n",
    "            \n",
    "            new_centroids = self.calcular_centroides(points, labels)\n",
    "\n",
    "            if np.array_equal(self.centroids, new_centroids):\n",
    "                break\n",
    "\n",
    "            self.centroids = new_centroids\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_inercia(points, labels, centroids):\n",
    "    inertia = 0\n",
    "    for i in range(len(centroids)):\n",
    "        cluster_points = points[labels == i]\n",
    "        if len(cluster_points) > 0:\n",
    "            inertia += np.sum((cluster_points - centroids[i])**2)\n",
    "    return inertia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRUPO 7\n",
    "\n",
    "MAUSEL PEREZ,\n",
    "WALDIR TOSCANO,\n",
    "JORGE ACOSTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimento 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimentos con 10 iteraciones\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inercias para 10 iteraciones: [np.float64(1716280.1867614654), np.float64(1660569.359944163), np.float64(1681862.384699723), np.float64(1711855.7750899903), np.float64(1743103.9139182973)]\n",
      "Inercia promedio: 1702734.3240827278\n",
      "Fin experimentos con 10 iteraciones\n",
      "\n",
      "Experimentos con 100 iteraciones\n",
      "Inercias para 100 iteraciones: [np.float64(1756522.3107013656), np.float64(2278435.4725329545), np.float64(1694200.613198673), np.float64(1694200.613198673), np.float64(1803413.0405767695)]\n",
      "Inercia promedio: 1845354.4100416868\n",
      "Fin experimentos con 100 iteraciones\n",
      "\n",
      "Experimentos con 1000 iteraciones\n",
      "Inercias para 1000 iteraciones: [np.float64(1712504.5764105418), np.float64(1802022.9590176994), np.float64(1742828.2980237757), np.float64(1681862.384699723), np.float64(2278361.436158196)]\n",
      "Inercia promedio: 1843515.9308619872\n",
      "Fin experimentos con 1000 iteraciones\n",
      "\n",
      "Experimentos con 10000 iteraciones\n",
      "Inercias para 10000 iteraciones: [np.float64(1712504.5764105418), np.float64(1788254.7333780343), np.float64(1712504.576410542), np.float64(1696588.2930236731), np.float64(1680885.5535219396)]\n",
      "Inercia promedio: 1718147.5465489463\n",
      "Fin experimentos con 10000 iteraciones\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parámetros del experimento\n",
    "n_samples = 1000\n",
    "n_features = 100  # 100 dimensiones\n",
    "k = 3\n",
    "max_iter = [10, 100, 1000, 10000]\n",
    "random_state = 456  # Cambiamos el random_state\n",
    "centers = 6  # Número de centros\n",
    "\n",
    "# Generación de datos\n",
    "points, y = make_blobs(n_samples=n_samples, n_features=n_features, centers=centers, random_state=random_state)\n",
    "\n",
    "# Ejecución del experimento\n",
    "for max_it in max_iter:\n",
    "    print(f\"Experimentos con {max_it} iteraciones\")\n",
    "    inercias = []\n",
    "    for i in range(5):  # Repetimos 5 veces para cada max_iter\n",
    "        kmeans = KMeans(k=k, max_iter=max_it)\n",
    "        labels = kmeans.run(points)\n",
    "        inertia = calcular_inercia(points, labels, kmeans.centroids)\n",
    "        inercias.append(inertia)\n",
    "    print(f\"Inercias para {max_it} iteraciones: {inercias}\")\n",
    "    print(f\"Inercia promedio: {np.mean(inercias)}\")\n",
    "    print(f\"Fin experimentos con {max_it} iteraciones\\n\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones\n",
    "\n",
    "--\n",
    "--\n",
    "--\n",
    "--\n",
    "--\n",
    "--\n",
    "--\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimento 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
